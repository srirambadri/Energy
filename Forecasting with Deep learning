{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from keras.layers import Dense,Dropout,SimpleRNN,LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = read_csv('Energy.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(dataset.index[[0,1,2]], inplace=True)\n",
    "# manually specify column names\n",
    "dataset.columns = ['datetime','SIB1001', 'HAR2002', 'TIM2002']\n",
    "# summarize first 5 rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating the columns to get column names\n",
    "for col in dataset.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating subsets for univariate analysis\n",
    "SIB1001DF = dataset[['datetime', 'SIB1001']]\n",
    "HAR2002DF = dataset[['datetime', 'HAR2002']]\n",
    "TIM2002DF = dataset[['datetime', 'TIM2002']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis for SIB1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with missing data\n",
    "SIB1001DF = SIB1001DF.dropna()\n",
    "#checking missing data\n",
    "SIB1001DF.isna().sum()\n",
    "\n",
    "#column data type formatting\n",
    "SIB1001DF.datetime = pd.to_datetime(SIB1001DF.datetime)\n",
    "SIB1001DF.SIB1001 = pd.to_numeric(SIB1001DF.SIB1001)\n",
    "SIB1001DF.set_index(['datetime'], inplace = True)\n",
    "SIB1001DF.head()\n",
    "\n",
    "#visualize data before normalization\n",
    "SIB1001DF.plot(figsize=(16,4),legend=True)\n",
    "\n",
    "plt.title('Hourly power consumption data - BEFORE NORMALIZATION')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#normalize data\n",
    "def normalize_data(SIB1001DF):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    SIB1001DF['SIB1001']=scaler.fit_transform(SIB1001DF['SIB1001'].values.reshape(-1,1))\n",
    "    return SIB1001DF\n",
    "SIB1001DF_norm = normalize_data(SIB1001DF)\n",
    "SIB1001DF_norm.shape\n",
    "\n",
    "#visualize data after normalization\n",
    "SIB1001DF_norm.plot(figsize=(16,4),legend=True)\n",
    "plt.title('SIB1001 hourly power consumption data - AFTER NORMALIZATION')\n",
    "plt.show()\n",
    "\n",
    "SIB1001DF_norm.shape\n",
    "\n",
    "#prepare data for training the RNN models\n",
    "def load_data(stock, seq_len):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(seq_len, len(stock)):\n",
    "        X_train.append(stock.iloc[i-seq_len : i, 0])\n",
    "        y_train.append(stock.iloc[i, 0])\n",
    "    \n",
    "    #1 last 3187 days are going to be used in test\n",
    "    X_test = X_train[21000:]             \n",
    "    y_test = y_train[21000:]\n",
    "    \n",
    "    #2 first 21000 days are going to be used in training\n",
    "    X_train = X_train[:21000]           \n",
    "    y_train = y_train[:21000]\n",
    "    \n",
    "    #3 convert to numpy array\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    #4 reshape data to input into RNN models\n",
    "    X_train = np.reshape(X_train, (21000, seq_len, 1))\n",
    "    \n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "#create train, test data\n",
    "seq_len = 20 #choose sequence length\n",
    "X_train, y_train, X_test, y_test = load_data(SIB1001DF, seq_len)\n",
    "print('X_train.shape = ',X_train.shape)\n",
    "print('y_train.shape = ', y_train.shape)\n",
    "print('X_test.shape = ', X_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)\n",
    "X_train.shape =  (21000, 20, 1)\n",
    "y_train.shape =  (21000,)\n",
    "X_test.shape =  (3797, 20, 1)\n",
    "y_test.shape =  (3797,)\n",
    "\n",
    "#build a simple RNN model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=False))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(Dense(1))\n",
    "rnn_model.summary()\n",
    "\n",
    "#evaluate model performance\n",
    "rnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "rnn_model.fit(X_train, y_train, epochs=50, batch_size=256)\n",
    "\n",
    "#check r2 scores\n",
    "rnn_predictions = rnn_model.predict(X_test)\n",
    "rnn_score = r2_score(y_test,rnn_predictions)\n",
    "print(\"R2 Score of RNN model: \",rnn_score)\n",
    "\n",
    "# Mean Forecast Error\n",
    "forecast_errors = [y_test[i]-rnn_predictions[i] for i in range(len(y_test))]\n",
    "bias = sum(forecast_errors) * 1.0/len(y_test)\n",
    "print('Bias: %f' % bias)\n",
    "\n",
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, rnn_predictions)\n",
    "print('MAE: %f' % mae)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "mse = mean_squared_error(y_test, rnn_predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %f' % rmse)\n",
    "\n",
    "#compare the actual values vs predicted values by plotting a graph\n",
    "def plot_predictions(test, predicted, title):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(test, color='blue',label='Actual power consumption data')\n",
    "    plt.plot(predicted, alpha=0.7, color='orange',label='Predicted power consumption data')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Normalized power consumption scale')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_predictions(y_test, rnn_predictions, \"SIB1001 Predictions made by simple RNN model\")\n",
    "\n",
    "#build an LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=False))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.summary()\n",
    "\n",
    "#evaluate model performance\n",
    "lstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=256)\n",
    "\n",
    "#check r2 score\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "lstm_score = r2_score(y_test, lstm_predictions)\n",
    "print(\"R^2 Score of LSTM model: \",lstm_score)\n",
    "\n",
    "# Forecast Mean Error\n",
    "forecast_errors = [y_test[i]-lstm_predictions[i] for i in range(len(y_test))]\n",
    "bias = sum(forecast_errors) * 1.0/len(y_test)\n",
    "print('Bias: %f' % bias)\n",
    "\n",
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, lstm_predictions)\n",
    "print('MAE: %f' % mae)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "mse = mean_squared_error(y_test, lstm_predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %f' % rmse)\n",
    "\n",
    "#compare the actual values vs predicted values by plotting a graph\n",
    "plot_predictions(y_test, lstm_predictions, \"SIB1001 Predictions made by LSTM model\")\n",
    "\n",
    "#compare predictions made by simple RNN and LSTM model by plotting data in a single graph\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(y_test, c=\"orange\", linewidth=3, label=\"Original values\")\n",
    "plt.plot(lstm_predictions, c=\"red\", linewidth=3, label=\"LSTM predictions\")\n",
    "plt.plot(rnn_predictions, alpha=0.5, c=\"green\", linewidth=3, label=\"RNN predictions\")\n",
    "plt.legend()\n",
    "plt.title(\"SIB1001 Predictions vs Actual Data\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis for HAR2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with missing data\n",
    "HAR2002DF = HAR2002DF.dropna()\n",
    "#checking missing data\n",
    "HAR2002DF.isna().sum()\n",
    "\n",
    "#column data type formatting\n",
    "HAR2002DF.datetime = pd.to_datetime(HAR2002DF.datetime)\n",
    "HAR2002DF.HAR2002 = pd.to_numeric(HAR2002DF.HAR2002)\n",
    "HAR2002DF.set_index(['datetime'], inplace = True)\n",
    "HAR2002DF.head()\n",
    "\n",
    "#visualize data before normalization\n",
    "HAR2002DF.plot(figsize=(16,4),legend=True)\n",
    "\n",
    "plt.title('Hourly power consumption data - BEFORE NORMALIZATION')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#normalize data\n",
    "def normalize_data(HAR2002DF):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    HAR2002DF['HAR2002']=scaler.fit_transform(HAR2002DF['HAR2002'].values.reshape(-1,1))\n",
    "    return HAR2002DF\n",
    "HAR2002DF_norm = normalize_data(HAR2002DF)\n",
    "HAR2002DF_norm.shape\n",
    "\n",
    "#visualize data after normalization\n",
    "HAR2002DF_norm.plot(figsize=(16,4),legend=True)\n",
    "plt.title('HAR2002 hourly power consumption data - AFTER NORMALIZATION')\n",
    "plt.show()\n",
    "\n",
    "HAR2002DF_norm.shape\n",
    "\n",
    "#prepare data for training the RNN models\n",
    "def load_data(stock, seq_len):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(seq_len, len(stock)):\n",
    "        X_train.append(stock.iloc[i-seq_len : i, 0])\n",
    "        y_train.append(stock.iloc[i, 0])\n",
    "    \n",
    "    #1 last 3187 days are going to be used in test\n",
    "    X_test = X_train[21000:]             \n",
    "    y_test = y_train[21000:]\n",
    "    \n",
    "    #2 first 21000 days are going to be used in training\n",
    "    X_train = X_train[:21000]           \n",
    "    y_train = y_train[:21000]\n",
    "    \n",
    "    #3 convert to numpy array\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    #4 reshape data to input into RNN models\n",
    "    X_train = np.reshape(X_train, (21000, seq_len, 1))\n",
    "    \n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "#create train, test data\n",
    "seq_len = 20 #choose sequence length\n",
    "X_train, y_train, X_test, y_test = load_data(HAR2002DF, seq_len)\n",
    "print('X_train.shape = ',X_train.shape)\n",
    "print('y_train.shape = ', y_train.shape)\n",
    "print('X_test.shape = ', X_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)\n",
    "\n",
    "\n",
    "#build a simple RNN model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=False))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(Dense(1))\n",
    "rnn_model.summary()\n",
    "\n",
    "#evaluate model performance\n",
    "rnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "rnn_model.fit(X_train, y_train, epochs=50, batch_size=256)\n",
    "\n",
    "#check r2 scores\n",
    "rnn_predictions = rnn_model.predict(X_test)\n",
    "rnn_score = r2_score(y_test,rnn_predictions)\n",
    "print(\"R2 Score of RNN model: \",rnn_score)\n",
    "\n",
    "# Mean Forecast Error\n",
    "forecast_errors = [y_test[i]-rnn_predictions[i] for i in range(len(y_test))]\n",
    "bias = sum(forecast_errors) * 1.0/len(y_test)\n",
    "print('Bias: %f' % bias)\n",
    "\n",
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, rnn_predictions)\n",
    "print('MAE: %f' % mae)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "mse = mean_squared_error(y_test, rnn_predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %f' % rmse)\n",
    "\n",
    "#compare the actual values vs predicted values by plotting a graph\n",
    "def plot_predictions(test, predicted, title):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(test, color='blue',label='Actual power consumption data')\n",
    "    plt.plot(predicted, alpha=0.7, color='orange',label='Predicted power consumption data')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Normalized power consumption scale')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_predictions(y_test, rnn_predictions, \"HAR2002 Predictions made by simple RNN model\")\n",
    "\n",
    "#build an LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=False))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.summary()\n",
    "\n",
    "#evaluate model performance\n",
    "lstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=256)\n",
    "\n",
    "#check r2 score\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "lstm_score = r2_score(y_test, lstm_predictions)\n",
    "print(\"R^2 Score of LSTM model: \",lstm_score)\n",
    "\n",
    "# Forecast Mean Error\n",
    "forecast_errors = [y_test[i]-lstm_predictions[i] for i in range(len(y_test))]\n",
    "bias = sum(forecast_errors) * 1.0/len(y_test)\n",
    "print('Bias: %f' % bias)\n",
    "\n",
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, lstm_predictions)\n",
    "print('MAE: %f' % mae)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "mse = mean_squared_error(y_test, lstm_predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %f' % rmse)\n",
    "\n",
    "#compare the actual values vs predicted values by plotting a graph\n",
    "plot_predictions(y_test, lstm_predictions, \"HAR2002 Predictions made by LSTM model\")\n",
    "\n",
    "#compare predictions made by simple RNN and LSTM model by plotting data in a single graph\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(y_test, c=\"orange\", linewidth=3, label=\"Original values\")\n",
    "plt.plot(lstm_predictions, c=\"red\", linewidth=3, label=\"LSTM predictions\")\n",
    "plt.plot(rnn_predictions, alpha=0.5, c=\"green\", linewidth=3, label=\"RNN predictions\")\n",
    "plt.legend()\n",
    "plt.title(\"HAR2002 Predictions vs Actual Data\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis for TIM2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with missing data\n",
    "TIM2002DF = TIM2002DF.dropna()\n",
    "#checking missing data\n",
    "TIM2002DF.isna().sum()\n",
    "\n",
    "#column data type formatting\n",
    "TIM2002DF.datetime = pd.to_datetime(TIM2002DF.datetime)\n",
    "TIM2002DF.TIM2002 = pd.to_numeric(TIM2002DF.TIM2002)\n",
    "TIM2002DF.set_index(['datetime'], inplace = True)\n",
    "TIM2002DF.head()\n",
    "\n",
    "#visualize data before normalization\n",
    "TIM2002DF.plot(figsize=(16,4),legend=True)\n",
    "\n",
    "plt.title('Hourly power consumption data - BEFORE NORMALIZATION')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#normalize data\n",
    "def normalize_data(TIM2002DF):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    TIM2002DF['TIM2002']=scaler.fit_transform(TIM2002DF['TIM2002'].values.reshape(-1,1))\n",
    "    return TIM2002DF\n",
    "TIM2002DF_norm = normalize_data(TIM2002DF)\n",
    "TIM2002DF_norm.shape\n",
    "\n",
    "#visualize data after normalization\n",
    "TIM2002DF_norm.plot(figsize=(16,4),legend=True)\n",
    "plt.title('TIM2002 hourly power consumption data - AFTER NORMALIZATION')\n",
    "plt.show()\n",
    "\n",
    "TIM2002DF_norm.shape\n",
    "\n",
    "#prepare data for training the RNN models\n",
    "def load_data(stock, seq_len):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(seq_len, len(stock)):\n",
    "        X_train.append(stock.iloc[i-seq_len : i, 0])\n",
    "        y_train.append(stock.iloc[i, 0])\n",
    "    \n",
    "    #1 last 3187 days are going to be used in test\n",
    "    X_test = X_train[21000:]             \n",
    "    y_test = y_train[21000:]\n",
    "    \n",
    "    #2 first 21000 days are going to be used in training\n",
    "    X_train = X_train[:21000]           \n",
    "    y_train = y_train[:21000]\n",
    "    \n",
    "    #3 convert to numpy array\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    #4 reshape data to input into RNN models\n",
    "    X_train = np.reshape(X_train, (21000, seq_len, 1))\n",
    "    \n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "#create train, test data\n",
    "seq_len = 20 #choose sequence length\n",
    "X_train, y_train, X_test, y_test = load_data(TIM2002DF, seq_len)\n",
    "print('X_train.shape = ',X_train.shape)\n",
    "print('y_train.shape = ', y_train.shape)\n",
    "print('X_test.shape = ', X_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)\n",
    "X_train.shape =  (21000, 20, 1)\n",
    "y_train.shape =  (21000,)\n",
    "X_test.shape =  (3797, 20, 1)\n",
    "y_test.shape =  (3797,)\n",
    "\n",
    "#build a simple RNN model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=False))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "rnn_model.add(Dense(1))\n",
    "rnn_model.summary()\n",
    "\n",
    "#evaluate model performance\n",
    "rnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "rnn_model.fit(X_train, y_train, epochs=50, batch_size=256)\n",
    "\n",
    "#check r2 scores\n",
    "rnn_predictions = rnn_model.predict(X_test)\n",
    "rnn_score = r2_score(y_test,rnn_predictions)\n",
    "print(\"R2 Score of RNN model: \",rnn_score)\n",
    "\n",
    "# Mean Forecast Error\n",
    "forecast_errors = [y_test[i]-rnn_predictions[i] for i in range(len(y_test))]\n",
    "bias = sum(forecast_errors) * 1.0/len(y_test)\n",
    "print('Bias: %f' % bias)\n",
    "\n",
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, rnn_predictions)\n",
    "print('MAE: %f' % mae)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "mse = mean_squared_error(y_test, rnn_predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %f' % rmse)\n",
    "\n",
    "#compare the actual values vs predicted values by plotting a graph\n",
    "def plot_predictions(test, predicted, title):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(test, color='blue',label='Actual power consumption data')\n",
    "    plt.plot(predicted, alpha=0.7, color='orange',label='Predicted power consumption data')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Normalized power consumption scale')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_predictions(y_test, rnn_predictions, \"TIM2002 Predictions made by simple RNN model\")\n",
    "\n",
    "#build an LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=False))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.summary()\n",
    "\n",
    "#evaluate model performance\n",
    "lstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=256)\n",
    "\n",
    "#check r2 score\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "lstm_score = r2_score(y_test, lstm_predictions)\n",
    "print(\"R^2 Score of LSTM model: \",lstm_score)\n",
    "\n",
    "# Forecast Mean Error\n",
    "forecast_errors = [y_test[i]-lstm_predictions[i] for i in range(len(y_test))]\n",
    "bias = sum(forecast_errors) * 1.0/len(y_test)\n",
    "print('Bias: %f' % bias)\n",
    "\n",
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, lstm_predictions)\n",
    "print('MAE: %f' % mae)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "mse = mean_squared_error(y_test, lstm_predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %f' % rmse)\n",
    "\n",
    "#compare the actual values vs predicted values by plotting a graph\n",
    "plot_predictions(y_test, lstm_predictions, \"TIM2002 Predictions made by LSTM model\")\n",
    "\n",
    "#compare predictions made by simple RNN and LSTM model by plotting data in a single graph\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(y_test, c=\"orange\", linewidth=3, label=\"Original values\")\n",
    "plt.plot(lstm_predictions, c=\"red\", linewidth=3, label=\"LSTM predictions\")\n",
    "plt.plot(rnn_predictions, alpha=0.5, c=\"green\", linewidth=3, label=\"RNN predictions\")\n",
    "plt.legend()\n",
    "plt.title(\"TIM2002 Predictions vs Actual Data\", fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
